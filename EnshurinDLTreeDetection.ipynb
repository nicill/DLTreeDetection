{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d7db48-a626-4bea-b962-309327a74638",
   "metadata": {},
   "source": [
    "# Tree Detection with Enshurin Data Using Deep Learning\n",
    "\n",
    "In this notebook we will use several Deep Learning networks to detect trees of the several species in RGB and multispectral mosaics of Data Acquired in Enshurin. We will consider the following species:  \n",
    "\n",
    "- Beech\n",
    "- Oak\n",
    "- Birch\n",
    "- Larch\n",
    "- Magnolia\n",
    "\n",
    "The data was collected by Vladislav Bukin.\n",
    "\n",
    "## Prerequisites.\n",
    "\n",
    "- Due to the size of the networks, this code will not run in free google colab. Either paid colab or running in locally in a computer with GPU is necessary. In the following I will assume that the code is run in a local computer that has a GPU and is CUDA-capable.\n",
    "- The computer needs to have software to run Python and jupyter notebook. `Anaconda` is recommended. If you are reading this, you most likely have already solved this part.\n",
    "- Apart from this, you need to create a proper virtual environment to run the code into. I recomment creating the environment with `Anaconda` itself and then installing packages using `pip`. At the very least you will need to install:\n",
    "    - opencv (for general image handling)\n",
    "    - pytorch (for general DL computations and the following models fasterRCNN, convnextMaskRCNN, maskRCNN, FCOS, retinanet, SSD  \n",
    "    - ultralytics for YOLO\n",
    "    - Transformers for DETR\n",
    "    - several other smaller libraries for several dependencies.\n",
    "\n",
    "# Getting Started\n",
    "\n",
    "Let's start by checking wheher or not the notebook has access to CUDA at this moment as it will determine whether or not you can run experiments on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05c6e88-b487-4214-966e-b2d9df2601e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x/anaconda3/envs/YOLO/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Make a cell with all necessary imports \"only\"\n",
    "import configparser\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from random import randint\n",
    "\n",
    "from datasets import TDDataset\n",
    "\n",
    "from config import read_config\n",
    "from imageUtils import boxesFound,read_Color_Image,read_Binary_Mask,recoupMasks, sliding_window, boxCoordsToFile\n",
    "from train import train_YOLO,makeTrainYAML, get_transform, train_pytorchModel,train_DETR, train_DeformableDETR\n",
    "\n",
    "from dataHandling import computeBBfromLIEnshurin, filterBoxesWindow, filterBoxesWindowNormalized\n",
    "\n",
    "#from dataHandling import (buildTRVT,buildNewDataTesting,separateTrainTest, \n",
    "#                           forPytorchFromYOLO, buildTestingFromSingleFolderSakuma2, \n",
    "#                           buildTestingFromSingleFolderSakuma2NOGT,\n",
    "#                           makeParamDicts, paramsDictToString)\n",
    "from predict import predict_yolo, predict_pytorch\n",
    "\n",
    "from experimentsUtils import MODULARDLExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dacb6da-0a2f-4ec4-9f95-bf69357a5bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS CUDA AVAILABLE???????????????????????\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# checking that CUDA is available\n",
    "print(\"IS CUDA AVAILABLE???????????????????????\")\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffecc367-b3c2-40f6-9d36-4ec476b1bba3",
   "metadata": {},
   "source": [
    "# Data preprocessing:\n",
    "\n",
    "Make sure to have the data, in this case files `Enshurin_2024_08_22_60m_ORTHO_СUT.tif` and `label_image_INT8.png`. In the same folder. In the following cell we define the path to that folder (relative to the folder that contains the notebook) and call a function to turn the mosaic into a series of tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29bb5e0c-61c9-4a81-9913-97a2dd040487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bounding_boxes(\n",
    "    mosaic, boxes, num_slices=50, slice_size=(1024, 1024), save_to_disk=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize sliding-window slices of the mosaic with bounding boxes.\n",
    "\n",
    "    Slices are:\n",
    "      • extracted in raster-scan order (top→bottom, left→right)\n",
    "      • always slice_size (unless touching image border)\n",
    "      • black slices are skipped (not counted toward num_slices)\n",
    "      • saved images include drawn bounding boxes\n",
    "      • Matplotlib visualization also shows bounding boxes\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    mosaic : np.ndarray (H,W,3)\n",
    "        The full RGB image.\n",
    "    boxes : list of (x, y, w, h, category)\n",
    "    num_slices : int\n",
    "        Number of slices to *save/visualize* (after skipping black ones)\n",
    "    slice_size : (H, W)\n",
    "        Desired slice size\n",
    "    save_to_disk : bool\n",
    "        Save slices as PNGs\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    import matplotlib\n",
    "\n",
    "    H, W = mosaic.shape[:2]\n",
    "    sh, sw = slice_size\n",
    "    saved = 0\n",
    "\n",
    "    # Category → color\n",
    "    colors = {\n",
    "        1: \"red\",\n",
    "        2: \"blue\",\n",
    "        3: \"green\",\n",
    "        4: \"yellow\",\n",
    "        5: \"cyan\",\n",
    "    }\n",
    "\n",
    "    # matplotlib figure for visualization\n",
    "    fig, axes = plt.subplots(1, num_slices, figsize=(4 * num_slices, 4))\n",
    "    if num_slices == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    ax_index = 0  # which subplot to draw into\n",
    "\n",
    "    # Slide in raster-scan order\n",
    "    for y0 in range(0, H, sh):\n",
    "        for x0 in range(0, W, sw):\n",
    "\n",
    "            if saved >= num_slices:\n",
    "                break\n",
    "\n",
    "            y1 = min(y0 + sh, H)\n",
    "            x1 = min(x0 + sw, W)\n",
    "\n",
    "            slice_img = mosaic[y0:y1, x0:x1]\n",
    "\n",
    "            # Skip black slices\n",
    "            if np.sum(slice_img) == 0:\n",
    "                continue\n",
    "\n",
    "            # Draw slice in matplotlib\n",
    "            ax = axes[ax_index]\n",
    "            ax.imshow(slice_img)\n",
    "            ax.set_title(f\"Slice {saved+1}\\n({x0}, {y0})\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "            # Copy for saving (so we draw boxes onto the saved image too)\n",
    "            save_img = slice_img.copy()\n",
    "\n",
    "            # Draw bounding boxes (both in Matplotlib and saved image)\n",
    "            for (px, py, bw, bh, category) in boxes:\n",
    "\n",
    "                # Check intersection with slice\n",
    "                if (px < x1 and px + bw > x0 and py < y1 and py + bh > y0):\n",
    "\n",
    "                    rx = int(px - x0)\n",
    "                    ry = int(py - y0)\n",
    "                    bw = int(bw)\n",
    "                    bh = int(bh)\n",
    "\n",
    "                    # Clamp boxes near borders\n",
    "                    if rx + bw < 0 or ry + bh < 0:\n",
    "                        continue\n",
    "\n",
    "                    color = colors.get(category, \"white\")\n",
    "\n",
    "                    # ----- Matplotlib rectangle -----\n",
    "                    rect = patches.Rectangle(\n",
    "                        (rx, ry), bw, bh, linewidth=2, edgecolor=color, facecolor=\"none\"\n",
    "                    )\n",
    "                    ax.add_patch(rect)\n",
    "                    ax.text(\n",
    "                        rx,\n",
    "                        ry - 5,\n",
    "                        str(category),\n",
    "                        color=color,\n",
    "                        fontsize=10,\n",
    "                        fontweight=\"bold\",\n",
    "                        bbox=dict(\n",
    "                            boxstyle=\"round,pad=0.3\", facecolor=\"black\", alpha=0.5\n",
    "                        ),\n",
    "                    )\n",
    "\n",
    "                    # ----- DRAW ON SAVED IMAGE (OpenCV) -----\n",
    "                    # Convert matplotlib color names to normalized RGB\n",
    "                    rgb = matplotlib.colors.to_rgb(color)  # floats 0–1\n",
    "                    bgr = tuple(int(255 * c) for c in rgb[::-1])\n",
    "\n",
    "                    cv2.rectangle(\n",
    "                        save_img, (rx, ry), (rx + bw, ry + bh), bgr, 2\n",
    "                    )\n",
    "                    cv2.putText(\n",
    "                        save_img,\n",
    "                        str(category),\n",
    "                        (rx, max(ry - 5, 0)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.6,\n",
    "                        bgr,\n",
    "                        2,\n",
    "                    )\n",
    "\n",
    "            # ----- SAVE PNG -----\n",
    "            if save_to_disk:\n",
    "                outname = f\"slice{saved+1}.png\"\n",
    "                cv2.imwrite(outname, cv2.cvtColor(save_img, cv2.COLOR_RGB2BGR))\n",
    "                print(f\"Saved {outname}\")\n",
    "\n",
    "            saved += 1\n",
    "            ax_index += 1\n",
    "\n",
    "        if saved >= num_slices:\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb05abad-56ee-4a3d-9b9a-9c371830ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_images(mosaic_file, label_file, scale_factor=0.5):\n",
    "    \"\"\"\n",
    "    Downsample mosaic and label images to reduce their size.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    mosaic_file : str\n",
    "        Path to the mosaic image file\n",
    "    label_file : str\n",
    "        Path to the label image file\n",
    "    scale_factor : float\n",
    "        Scaling factor (0.5 = half size, 0.25 = quarter size, etc.)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    mosaic_downsampled : numpy.ndarray\n",
    "        Downsampled mosaic image\n",
    "    label_downsampled : numpy.ndarray\n",
    "        Downsampled label image\n",
    "    \"\"\"\n",
    "    # Read images\n",
    "    mosaic = read_Color_Image(mosaic_file)\n",
    "    label = cv2.imread(label_file, cv2.IMREAD_UNCHANGED)  # Read as-is to preserve labels\n",
    "    \n",
    "    # Calculate new dimensions\n",
    "    new_width = int(mosaic.shape[1] * scale_factor)\n",
    "    new_height = int(mosaic.shape[0] * scale_factor)\n",
    "    new_size = (new_width, new_height)\n",
    "    \n",
    "    print(f\"Original size: {mosaic.shape[1]}x{mosaic.shape[0]}\")\n",
    "    print(f\"New size: {new_width}x{new_height}\")\n",
    "    \n",
    "    # Downsample mosaic using bilinear interpolation (smooth for RGB images)\n",
    "    mosaic_downsampled = cv2.resize(mosaic, new_size, interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # Downsample label image using nearest neighbor (preserves discrete label values)\n",
    "    label_downsampled = cv2.resize(label, new_size, interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    return mosaic_downsampled, label_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b2e1b-400f-4eca-bdc1-bdb6aa3e5c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VLAD's data\n",
    "\n",
    "dataFolder = \"./Data/Vlad\"\n",
    "labelImageFile = os.path.join(dataFolder,\"label_image_INT8.png\")\n",
    "mosaicFile = os.path.join(dataFolder,\"Enshurin_2024_08_22_60m_ORTHO_СUT.tif\")\n",
    "\n",
    "mosaic_half, label_half = downsample_images(mosaicFile, labelImageFile, scale_factor=0.5)\n",
    "cv2.imwrite('mosaic_half.png', cv2.cvtColor(mosaic_half, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite('label_half.png', label_half)\n",
    "\n",
    "mosaic_full, label_full = downsample_images(mosaicFile, labelImageFile, scale_factor=1)\n",
    "cv2.imwrite('mosaicPNG.png', cv2.cvtColor(mosaic_full, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite('labelPNG.png', label_full)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "040d21b7-9838-434d-a09c-389edd610cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lIMfile, mosFile, outFolderRoot, trainPerc, doYOLO, slice, verbose = True):\n",
    "    \"\"\"\n",
    "        Given a mosaic and a label image, create bounding boxes for the label image\n",
    "        then tile mosaic and boxes and store in a folder\n",
    "        if trainPerc != 0 then divide into train and test folders\n",
    "    \"\"\"\n",
    "    labelIM = cv2.imread(lIMfile,cv2.IMREAD_UNCHANGED)\n",
    "    # check unique labels read    \n",
    "    #print(np.unique(labelIM))\n",
    "    #print(labelIM.shape)\n",
    "\n",
    "    mosaic = read_Color_Image(mosFile)\n",
    "    boxes, boxesNorm = computeBBfromLIEnshurin(labelIM)\n",
    "    # Visualize bounding boxes\n",
    "    #if verbose:\n",
    "    #    visualize_bounding_boxes(mosaic, boxes, num_slices=200, slice_size=(1024, 1024))\n",
    "\n",
    "    # If the train percentage is  0 then we are making one single folder \n",
    "    # otherwise, make one folder for trainining and one for validation\n",
    "    singleFolder = (trainPerc == 0)\n",
    "    \n",
    "    # create output folders if they do not exist, if mosaic mode create train andn test subfolders\n",
    "    Path(outFolderRoot).mkdir(parents=True, exist_ok=True)\n",
    "    if not singleFolder :\n",
    "        Path(os.path.join(outFolderRoot,\"train\")).mkdir(parents=True, exist_ok=True)\n",
    "        Path(os.path.join(outFolderRoot,\"validation\")).mkdir(parents=True, exist_ok=True)\n",
    "        if doYOLO:\n",
    "            Path(os.path.join(outFolderRoot,\"train\",\"images\")).mkdir(parents=True, exist_ok=True)\n",
    "            Path(os.path.join(outFolderRoot,\"train\",\"masks\")).mkdir(parents=True, exist_ok=True)\n",
    "            Path(os.path.join(outFolderRoot,\"train\",\"labels\")).mkdir(parents=True, exist_ok=True)\n",
    "            Path(os.path.join(outFolderRoot,\"validation\",\"images\")).mkdir(parents=True, exist_ok=True)\n",
    "            Path(os.path.join(outFolderRoot,\"validation\",\"masks\")).mkdir(parents=True, exist_ok=True)\n",
    "            Path(os.path.join(outFolderRoot,\"validation\",\"labels\")).mkdir(parents=True, exist_ok=True)\n",
    "    else:    \n",
    "        if doYOLO:\n",
    "            Path(os.path.join(outFolderRoot,\"images\")).mkdir(parents=True, exist_ok=True)\n",
    "            Path(os.path.join(outFolderRoot,\"masks\")).mkdir(parents=True, exist_ok=True)\n",
    "            Path(os.path.join(outFolderRoot,\"labels\")).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # add the name of the original image to every tile as a prefix (without extension)\n",
    "    outputPrefix = os.path.basename(mosFile)[:-4] \n",
    "    \n",
    "    # slice the three things and output\n",
    "    wSize = (slice,slice)\n",
    "    count = 0\n",
    "    for (x, y, window) in sliding_window(mosaic, stepSize = int(slice*0.8), windowSize = wSize ):\n",
    "        # get mask window\n",
    "        if window.shape[:2] == (slice,slice) :\n",
    "            labelW = labelIM[y:y + wSize[1], x:x + wSize[0]]\n",
    "            boxesW = filterBoxesWindow(boxes,y,y + wSize[1], x,x + wSize[0])\n",
    "            boxesWNorm = boxesWNorm = filterBoxesWindowNormalized(boxesNorm, y, y+slice, x, x+slice, full_w=mosaic.shape[1], full_h=mosaic.shape[0])\n",
    "\n",
    "            if verbose: print(boxesW)\n",
    "\n",
    "            # here we should probably add cleanUpMaskBlackPixels and maybe do it for YOLO too (in buildtrainvalidation?)\n",
    "            if len(boxesW) > 0:\n",
    "                # store them both, doing a randomDraw to see if they go to training or testing\n",
    "                outFolder = (outFolderRoot if singleFolder else \n",
    "                (os.path.join(outFolderRoot,\"train\") if randint(1,100) < trainPerc else os.path.join(outFolderRoot,\"validation\") ) )\n",
    "                if verbose: print(\"writing to \"+str(os.path.join(outFolder,\"Tile\"+str(count)+\".png\")))\n",
    "                if doYOLO:\n",
    "                    cv2.imwrite(os.path.join(outFolder, \"images\",outputPrefix+\"x\"+str(x)+\"y\"+str(y)+\".png\"),window)\n",
    "                    cv2.imwrite(os.path.join(outFolder,\"masks\",outputPrefix+\"x\"+str(x)+\"y\"+str(y)+\"MASK.png\"),labelW)\n",
    "                    boxCoordsToFile(os.path.join(outFolder,\"labels\",outputPrefix+\"x\"+str(x)+\"y\"+str(y)+\".txt\"),boxesWNorm)\n",
    "                else:                    \n",
    "                    cv2.imwrite(os.path.join(outFolder,outputPrefix+\"x\"+str(x)+\"y\"+str(y)+\".png\"),window)\n",
    "                    cv2.imwrite(os.path.join(outFolder,outputPrefix+\"x\"+str(x)+\"y\"+str(y)+\"Labels.tif\"),labelW)\n",
    "                    boxCoordsToFile(os.path.join(outFolder,outputPrefix+\"x\"+str(x)+\"y\"+str(y)+\"Boxes.txt\"),boxesW)\n",
    "                count+=1\n",
    "            else:\n",
    "                if verbose: print(\"no boxes here\")\n",
    "        else:\n",
    "            if verbose:  print(\"sliceFolder, non full window, ignoring\"+str(window.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228d6210-b849-4bfe-88c9-33babb3c7f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder = \"./Data/Vlad\"\n",
    "#labelImageFile = os.path.join(dataFolder,\"label_image_INT8.png\")\n",
    "#mosaicFile = os.path.join(dataFolder,\"Enshurin_2024_08_22_60m_ORTHO_СUT.tif\")\n",
    "labelImageFile = os.path.join(dataFolder,\"label_half.png\")\n",
    "mosaicFile = os.path.join(dataFolder,\"mosaic_half.png\")\n",
    "#labelImageFile = os.path.join(dataFolder,\"labelPNG.png\")\n",
    "#mosaicFile = os.path.join(dataFolder,\"mosaicPNG.png\")\n",
    "\n",
    "outputFolder = os.path.join(dataFolder,\"processedData\")\n",
    "\n",
    "prepareData(labelImageFile,mosaicFile,outputFolder, 80, 2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950fe93d-6ded-4ba9-bc9c-3cbfd9ed9dd8",
   "metadata": {},
   "source": [
    "# Sarangerel's data\n",
    "\n",
    "First of all, as I am having trouble with the tiff format, I will change everything to png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d2d844-f2f3-4802-a8e4-01d198aa1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder = os.path.join(os.getcwd(), \"Data\", \"NART\") \n",
    "\n",
    "inputTrain = os.path.join(dataFolder,\"train\")\n",
    "trainData = os.path.join(dataFolder,\"processedTrain\")\n",
    "\n",
    "inputTest = os.path.join(dataFolder,\"test\")\n",
    "testData = os.path.join(dataFolder,\"processedTest\")\n",
    "\n",
    "sliceSize = 500\n",
    "trainPercentage = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b5f725b-e79a-46d0-9d92-6e7f003ffe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not needed!\n",
    "def convert_tif_to_png(folder_path):\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.tif', '.tiff')):\n",
    "                tif_path = os.path.join(root, file)\n",
    "                png_path = os.path.splitext(tif_path)[0] + '.png'\n",
    "                img = read_Color_Image(tif_path)\n",
    "                if img is not None:\n",
    "                    cv2.imwrite(png_path, img)\n",
    "                    print(f\"✓ {file} → {os.path.basename(png_path)}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3517dc6-e50d-43bc-a4db-22811aaad8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not needed!\n",
    "# call the function to convert tif to png\n",
    "convert_tif_to_png(os.path.join(dataFolder,\"test_image\"))\n",
    "convert_tif_to_png(os.path.join(dataFolder,\"test_label\"))\n",
    "convert_tif_to_png(os.path.join(dataFolder,\"train_image\"))\n",
    "convert_tif_to_png(os.path.join(dataFolder,\"train_label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5649f947-3143-43b4-9039-7f4fac1ab877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliceAndBoxNartData(prefix, outputFolder, sliceSize = 500, trainPerc = 0):\n",
    "    \"\"\"\n",
    "        receive one folder divided into prefi_image and \n",
    "        prefix_mask, one slice size in pixels\n",
    "        traverse all images in the \"image\" folder\n",
    "        make sure that they have a corresponding mask.\n",
    "        Slice and box them all into an outputFolder\n",
    "    \"\"\"\n",
    "    for root, _, files in os.walk(prefix+\"_image\"):\n",
    "        for imageFile in files:\n",
    "            labelImageFile = os.path.join(prefix+\"_mask\",imageFile)\n",
    "            if os.path.isfile( labelImageFile ):\n",
    "                prepareData(labelImageFile,os.path.join(prefix+\"_image\",imageFile),outputFolder, 0, False, sliceSize, verbose = False)\n",
    "                prepareData(labelImageFile,os.path.join(prefix+\"_image\",imageFile),outputFolder, trainPerc, True, sliceSize, verbose = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4cefd22-065b-403d-878c-7d8081ee7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all of our images to masks, box files and slices\n",
    "# make one folder for training YOLO\n",
    "sliceAndBoxNartData(inputTrain,trainData, sliceSize = sliceSize, trainPerc = trainPercentage)\n",
    "# also make one folder for testing\n",
    "sliceAndBoxNartData(inputTest,testData, sliceSize = sliceSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63146342-32cb-4d83-83f3-43e6a048aaf9",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba310360-8c43-4e57-8836-4dfb06863cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration of our experiments\n",
    "conf = {\n",
    "    \"Prep\" : False,\n",
    "    \"Train\" : True,\n",
    "    \"ep\" : 5,\n",
    "    \"numClasses\" : 3,\n",
    "    \"Train_Perc\" : trainPercentage,\n",
    "    \"slice\": sliceSize,\n",
    "    \"TV_dir\" : os.path.join(dataFolder,\"processedTrain\"),\n",
    "    \"Train_dir\" : \"train\",\n",
    "    \"Valid_dir\" : \"validation\",\n",
    "    \"Pred_dir\" : \"YoloPredictions\",\n",
    "    \"Test_dir\" : os.path.join(dataFolder,\"processedTest\"),\n",
    "    \"Train_res\": os.path.join(os.getcwd(), \"YOLOResults\"),\n",
    "    \"Valid_res\": os.path.join(os.getcwd(), \"YOLOResults\"),\n",
    "    \"outTEXT\": \"./results.txt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024c811-e6ba-4d18-aad7-53a8401b4a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing datasets...\n",
      "\n",
      "=== Running PyTorch Model Experiment ===\n",
      "Parameters: {'modelType': 'maskrcnn', 'score': 0.25, 'nms': 0.5, 'predconf': 0.7}\n",
      "Train dataset length: 529\n",
      "Testing params {'modelType': 'maskrcnn', 'score': 0.25, 'nms': 0.5, 'predconf': 0.7} with file expmodelTypemaskrcnnscore0.25nms0.5Epochs5.pth\n",
      "Inside Pytorch training Training Dataset Length 529\n",
      "train again\n",
      "get_model_instance_segmentation 4\n",
      "cls out: 4\n",
      "mask out: 4\n",
      "maskrcnn\n",
      "have the model\n",
      "Epoch: [0]  [  0/529]  eta: 0:04:29  lr: 0.000014  loss: 3.9697 (3.9697)  loss_classifier: 1.4229 (1.4229)  loss_box_reg: 0.2936 (0.2936)  loss_mask: 1.3924 (1.3924)  loss_objectness: 0.7630 (0.7630)  loss_rpn_box_reg: 0.0977 (0.0977)  time: 0.5097  data: 0.1954  max mem: 9707\n",
      "Epoch: [0]  [ 10/529]  eta: 0:03:23  lr: 0.000109  loss: 3.9772 (4.1838)  loss_classifier: 1.4125 (1.4066)  loss_box_reg: 0.1368 (0.1819)  loss_mask: 1.5058 (1.5566)  loss_objectness: 0.8426 (0.9743)  loss_rpn_box_reg: 0.0568 (0.0642)  time: 0.3920  data: 0.0179  max mem: 9707\n",
      "Epoch: [0]  [ 20/529]  eta: 0:03:16  lr: 0.000204  loss: 3.9772 (4.1705)  loss_classifier: 1.3667 (1.3441)  loss_box_reg: 0.1183 (0.1597)  loss_mask: 1.5420 (1.5511)  loss_objectness: 0.8547 (1.0500)  loss_rpn_box_reg: 0.0552 (0.0656)  time: 0.3798  data: 0.0002  max mem: 9707\n",
      "Epoch: [0]  [ 30/529]  eta: 0:03:14  lr: 0.000298  loss: 3.8439 (4.0819)  loss_classifier: 1.1549 (1.2517)  loss_box_reg: 0.1362 (0.1783)  loss_mask: 1.4130 (1.5019)  loss_objectness: 1.0505 (1.0813)  loss_rpn_box_reg: 0.0623 (0.0687)  time: 0.3881  data: 0.0002  max mem: 9707\n"
     ]
    }
   ],
   "source": [
    "doYolo = False\n",
    "doPytorch = True\n",
    "doDETR = False\n",
    "\n",
    "yolo_params = {\"scale\": 0.3, \"mosaic\": 0.5} if doYolo else None\n",
    "pytorch_params = {\"modelType\": \"maskrcnn\", \"score\": 0.25, \"nms\": 0.5, \"predconf\": 0.7} if doPytorch else None\n",
    "detr_params = {\"modelType\": \"DETR\", \"lr\": 5e-6, \"batch_size\": 8, \"predconf\": 0.5, \n",
    "               \"nms_iou\": 0.5, \"max_detections\": 50, \"resize\": 800} if doDETR else None\n",
    "\n",
    "# Run experiments\n",
    "MODULARDLExperiment(conf, yolo_params, pytorch_params, detr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bfe1b5-2c6c-467d-9931-3f28155c08ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
